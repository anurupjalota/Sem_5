{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task_2_logistic_diabetes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BHdMfFcnf_Ki"
      },
      "source": [
        "## Logistic Regression Modeling for Early Stage Diabetes Risk Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94zrEAhOKeQ-",
        "colab_type": "text"
      },
      "source": [
        "## Part 2.1: Getting familiar with linear algebraic functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mu4NxtEKeQ_",
        "colab_type": "text"
      },
      "source": [
        "#### Tasks\n",
        "- Create matrix of size 10*10 with random integer numbers\n",
        "- Compute the following linear algebric operations on the matrix using built in functions supported in Numpy, Scipy etc.\n",
        "  - Find inverse of the matrix and print it\n",
        "  - Calculate dot product of the matrix with same matrix in transpose A.AT\n",
        "  - Decompose the original matrix using eigen decomposition print the eigen values and eigen vectors\n",
        "  - Calculate jacobian matrix \n",
        "  - Calculate hessian matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gspb2PwvOUuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3074474d-4c9e-416e-db29-3387abf976ae"
      },
      "source": [
        "pip install numdifftools"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numdifftools in /usr/local/lib/python3.6/dist-packages (0.9.39)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2odcpahRKeRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import numpy.linalg as lg\n",
        "import numdifftools as nd\n",
        "import sympy as sym"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r29b-DwQKeRD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "9969236b-7e9e-45fb-c7e1-55c6d7c9de7f"
      },
      "source": [
        "mat = np.random.randint(100, size=(10, 10))\n",
        "mat"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[95, 20, 83, 76, 53, 40, 72, 87, 11, 23],\n",
              "       [61, 38, 43, 22, 42, 57, 43, 64, 79, 89],\n",
              "       [43, 64, 56, 97,  0, 15, 38, 98, 67, 84],\n",
              "       [48, 41, 33, 72, 63, 49,  1, 14, 32,  8],\n",
              "       [16, 19, 69,  9, 36, 27, 62, 11,  3, 90],\n",
              "       [26, 83, 18,  1, 62, 60, 82, 60, 97,  6],\n",
              "       [24, 99, 49, 60, 30, 13, 28, 48,  3, 62],\n",
              "       [12, 79, 55, 99, 83, 11, 76, 61, 12,  0],\n",
              "       [52, 97, 25, 29,  2, 68, 64, 65, 15, 23],\n",
              "       [87, 76, 46, 26, 46, 88, 72, 11, 33, 70]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EChxATMWKeRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "c5661365-66ce-4b98-a002-8c00a6692495"
      },
      "source": [
        "inv = lg.inv(mat)\n",
        "inv"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01019044, -0.0010478 , -0.00060942, -0.01063625, -0.01576873,\n",
              "         0.0009914 ,  0.00977427, -0.00389072, -0.01392551,  0.01603822],\n",
              "       [ 0.00111341, -0.00959148,  0.00017607, -0.00035013, -0.00270928,\n",
              "         0.00773284,  0.01438026, -0.0069147 , -0.0035374 ,  0.0029038 ],\n",
              "       [ 0.01406608, -0.03500401,  0.00816283,  0.0189987 ,  0.02321253,\n",
              "         0.02267923,  0.01188142, -0.02969946, -0.00433023, -0.01297266],\n",
              "       [-0.00687823,  0.00078193,  0.007785  ,  0.00281269, -0.00187457,\n",
              "        -0.00920315, -0.01242903,  0.01124753,  0.00269522,  0.00492436],\n",
              "       [-0.00157491,  0.01987028, -0.01371566, -0.00274811, -0.00651873,\n",
              "        -0.005914  ,  0.00417878,  0.01180848, -0.00351506, -0.00163142],\n",
              "       [-0.0083436 ,  0.00627786, -0.00325896,  0.01727326,  0.01341269,\n",
              "        -0.0067287 , -0.01617692,  0.00092945,  0.02345368, -0.01334994],\n",
              "       [-0.00226648, -0.00135996,  0.00420905, -0.0134849 , -0.00201125,\n",
              "        -0.00209115, -0.01130414,  0.01208612, -0.00188472,  0.0123607 ],\n",
              "       [ 0.00119113,  0.01907862, -0.00824339, -0.00252963, -0.0026419 ,\n",
              "        -0.00657921,  0.0002603 ,  0.00528945,  0.01181674, -0.01461984],\n",
              "       [ 0.00159642, -0.01338493,  0.01091163,  0.00409646,  0.00163972,\n",
              "         0.01384167, -0.00016591, -0.00988461, -0.01049389,  0.00323163],\n",
              "       [-0.00764726,  0.01818908, -0.00275731, -0.00750264, -0.00288496,\n",
              "        -0.01210831, -0.00169709,  0.01015106,  0.00084656,  0.00381055]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7oxPXV9KeRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "e15d38ce-4725-4440-b98a-85e94197f981"
      },
      "source": [
        "np.dot(mat,mat.T)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[39902, 27882, 31916, 20716, 18823, 23715, 22648, 30559, 24942,\n",
              "        29651],\n",
              "       [27882, 32618, 31127, 17107, 19531, 27123, 20685, 20510, 22675,\n",
              "        30330],\n",
              "       [31916, 31127, 41308, 18481, 18241, 24434, 27304, 28090, 25416,\n",
              "        26928],\n",
              "       [20716, 17107, 18481, 17913,  9095, 16237, 14967, 19840, 14482,\n",
              "        19734],\n",
              "       [18823, 19531, 18241,  9095, 19558, 13671, 15470, 15083, 13367,\n",
              "        21260],\n",
              "       [23715, 27123, 24434, 16237, 13671, 35103, 18262, 24820, 24827,\n",
              "        27741],\n",
              "       [22648, 20685, 27304, 14967, 15470, 18262, 24388, 24469, 21143,\n",
              "        22933],\n",
              "       [30559, 20510, 28090, 19840, 15083, 24820, 24469, 35862, 22456,\n",
              "        23477],\n",
              "       [24942, 22675, 25416, 14482, 13367, 24827, 21143, 22456, 27282,\n",
              "        27304],\n",
              "       [29651, 30330, 26928, 19734, 21260, 27741, 22933, 23477, 27304,\n",
              "        37291]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2eoU-wtKeRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "5b5a3181-e7af-458d-dfad-3af8bb309b06"
      },
      "source": [
        "eigen = lg.eig(mat)\n",
        "print(\"eigen Values\")\n",
        "print(eigen[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eigen Values\n",
            "[477.97971537 +0.j          30.26362585+77.05736066j\n",
            "  30.26362585-77.05736066j  59.87804969+13.65867616j\n",
            "  59.87804969-13.65867616j   2.57978718+57.33714713j\n",
            "   2.57978718-57.33714713j -36.83469227+20.36049473j\n",
            " -36.83469227-20.36049473j -58.75325625 +0.j        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP8lBLVqM5zl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "2d14bd39-7dfb-4022-da1c-ec20c03ad1e7"
      },
      "source": [
        "print(\"Eigen Vectors\")\n",
        "print(eigen[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eigen Vectors\n",
            "[[ 0.36056068+0.j          0.10737013-0.37768017j  0.10737013+0.37768017j\n",
            "   0.68088271+0.j          0.68088271-0.j         -0.17163426+0.01326332j\n",
            "  -0.17163426-0.01326332j  0.12729154-0.09587795j  0.12729154+0.09587795j\n",
            "  -0.01781335+0.j        ]\n",
            " [ 0.36085524+0.j         -0.17268026-0.03985245j -0.17268026+0.03985245j\n",
            "  -0.06903844-0.0442612j  -0.06903844+0.0442612j   0.03618919+0.08343467j\n",
            "   0.03618919-0.08343467j  0.37342922-0.14202134j  0.37342922+0.14202134j\n",
            "   0.39475665+0.j        ]\n",
            " [ 0.37057865+0.j         -0.2477251 +0.06774681j -0.2477251 -0.06774681j\n",
            "   0.03741142+0.16449887j  0.03741142-0.16449887j  0.66018061+0.j\n",
            "   0.66018061-0.j          0.53076747+0.j          0.53076747-0.j\n",
            "   0.49327048+0.j        ]\n",
            " [ 0.22573076+0.j         -0.12014852-0.02410265j -0.12014852+0.02410265j\n",
            "  -0.07241493+0.10374532j -0.07241493-0.10374532j -0.129957  +0.20569049j\n",
            "  -0.129957  -0.20569049j -0.30589611-0.0611965j  -0.30589611+0.0611965j\n",
            "  -0.24176551+0.j        ]\n",
            " [ 0.23562478+0.j          0.23835861+0.39849748j  0.23835861-0.39849748j\n",
            "   0.07959718-0.15666726j  0.07959718+0.15666726j -0.20537101-0.48401772j\n",
            "  -0.20537101+0.48401772j  0.07262711-0.01703313j  0.07262711+0.01703313j\n",
            "  -0.00083815+0.j        ]\n",
            " [ 0.31708559+0.j          0.05797081-0.19996985j  0.05797081+0.19996985j\n",
            "  -0.60529846+0.05259299j -0.60529846-0.05259299j -0.14181902-0.03386465j\n",
            "  -0.14181902+0.03386465j -0.07719937+0.20495756j -0.07719937-0.20495756j\n",
            "   0.32583155+0.j        ]\n",
            " [ 0.27936984+0.j          0.05394718+0.22821691j  0.05394718-0.22821691j\n",
            "   0.063581  -0.06424974j  0.063581  +0.06424974j  0.11267386-0.02322583j\n",
            "   0.11267386+0.02322583j -0.39368075-0.19196117j -0.39368075+0.19196117j\n",
            "  -0.44846429+0.j        ]\n",
            " [ 0.29593984+0.j          0.50854266+0.j          0.50854266-0.j\n",
            "  -0.04458307+0.02008885j -0.04458307-0.02008885j -0.25335438-0.03066548j\n",
            "  -0.25335438+0.03066548j -0.11383461+0.31793203j -0.11383461-0.31793203j\n",
            "   0.01372674+0.j        ]\n",
            " [ 0.29671191+0.j         -0.18994195-0.22437997j -0.18994195+0.22437997j\n",
            "  -0.21749271+0.07123046j -0.21749271-0.07123046j  0.19652932+0.20517951j\n",
            "   0.19652932-0.20517951j -0.04435854-0.10379766j -0.04435854+0.10379766j\n",
            "  -0.43685184+0.j        ]\n",
            " [ 0.37652148+0.j         -0.24745764+0.11496339j -0.24745764-0.11496339j\n",
            "   0.06747082-0.13297866j  0.06747082+0.13297866j -0.09631014+0.03142255j\n",
            "  -0.09631014-0.03142255j -0.22296483+0.11871585j -0.22296483-0.11871585j\n",
            "  -0.20920915+0.j        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Ibor3uNKaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1, x2 = sym.symbols('x1 x2')\n",
        "f = sym.symbols('f', cls=sym.Function)\n",
        "\n",
        "X = sym.Matrix([x1,x2])\n",
        "f = sym.Matrix([x1**2 + x2**2 - 10])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p53QgKANvPVX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "786da528-13ad-4c89-b710-da5c3a53ebbb"
      },
      "source": [
        "sym.simplify(f.jacobian(X))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/latex": "$$\\left[\\begin{matrix}2 x_{1} & 2 x_{2}\\end{matrix}\\right]$$",
            "text/plain": [
              "[2⋅x₁  2⋅x₂]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al0yNPWaOZXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        },
        "outputId": "3a3be301-de6f-4f1c-ee8d-ab2fdef864fb"
      },
      "source": [
        "sym.simplify(hessian(f, X))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/latex": "$$\\left[\\begin{matrix}2 & 0\\\\0 & 2\\end{matrix}\\right]$$",
            "text/plain": [
              "⎡2  0⎤\n",
              "⎢    ⎥\n",
              "⎣0  2⎦"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6Qx6aadKeRQ",
        "colab_type": "text"
      },
      "source": [
        "## Part 2.2: Logistic Regression using newton method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1LWrifqkf_Kj"
      },
      "source": [
        "### Logistic regression\n",
        "Logistic regression uses an equation as the representation, very much like linear regression.\n",
        "\n",
        "Input values (x) are combined linearly using weights or coefficient values (referred to as W) to predict an output value (y). A key difference from linear regression is that the output value being modeled is a binary values (0 or 1) rather than a continuous value.<br>\n",
        "\n",
        "###  $\\hat{y}(w, x) = \\frac{1}{1+exp^{-(w_0 + w_1 * x_1 + ... + w_p * x_p)}}$\n",
        "\n",
        "#### Dataset\n",
        "The dataset is available at <strong>\"data/diabetes_data.csv\"</strong> in the respective challenge's repo.<br>\n",
        "<strong>Original Source:</strong> http://archive.ics.uci.edu/ml/machine-learning-databases/00529/diabetes_data_upload.csv. The dataset just got released in July 2020.<br><br>\n",
        "\n",
        "#### Features (X)\n",
        "\n",
        "1. Age                - Values ranging from 16-90\n",
        "2. Gender             - Binary value (Male/Female)\n",
        "3. Polyuria           - Binary value (Yes/No)\n",
        "4. Polydipsia         - Binary value (Yes/No)\n",
        "5. sudden weight loss - Binary value (Yes/No)\n",
        "6. weakness           - Binary value (Yes/No)\n",
        "7. Polyphagia         - Binary value (Yes/No)\n",
        "8. Genital thrush     - Binary value (Yes/No)\n",
        "9. visual blurring    - Binary value (Yes/No)\n",
        "10. Itching           - Binary value (Yes/No)\n",
        "11. Irritability      - Binary value (Yes/No)\n",
        "12. delayed healing   - Binary value (Yes/No)\n",
        "13. partial paresis   - Binary value (Yes/No)\n",
        "14. muscle stiffness  - Binary value (Yes/No)\n",
        "15. Alopecia          - Binary value (Yes/No)\n",
        "16. Obesity           - Binary value (Yes/No)\n",
        "\n",
        "#### Output/Target target (Y) \n",
        "17. class - Binary class (Positive/Negative)\n",
        "\n",
        "#### Objective\n",
        "To learn logistic regression and practice handling of both numerical and categorical features\n",
        "\n",
        "#### Tasks\n",
        "- Download, load the data and print first 5 and last 5 rows\n",
        "- Transform categorical features into numerical features. Use label encoding or any other suitable preprocessing technique\n",
        "- Since the age feature is in larger range, age column can be normalized into smaller scale (like 0 to 1) using different methods such as scaling, standardizing or any other suitable preprocessing technique (Example - sklearn.preprocessing.MinMaxScaler class)\n",
        "- Define X matrix (independent features) and y vector (target feature)\n",
        "- Split the dataset into 60% for training and rest 40% for testing (sklearn.model_selection.train_test_split function)\n",
        "- Train Logistic Regression Model on the training set (sklearn.linear_model.LogisticRegression class)\n",
        "- Use the trained model to predict on testing set\n",
        "- Print 'Accuracy' obtained on the testing dataset i.e. (sklearn.metrics.accuracy_score function)\n",
        "\n",
        "#### Further fun (will not be evaluated)\n",
        "- Plot loss curve (Loss vs number of iterations)\n",
        "- Preprocess data with different feature scaling methods (i.e. scaling, normalization, standardization, etc) and observe accuracies on both X_train and X_test\n",
        "- Training model on different train-test splits such as 60-40, 50-50, 70-30, 80-20, 90-10, 95-5 etc. and observe accuracies on both X_train and X_test\n",
        "- Shuffling of training samples with different *random seed values* in the train_test_split function. Check the model error for the testing data for each setup.\n",
        "- Print other classification metrics such as:\n",
        "    - classification report (sklearn.metrics.classification_report),\n",
        "    - confusion matrix (sklearn.metrics.confusion_matrix),\n",
        "    - precision, recall and f1 scores (sklearn.metrics.precision_recall_fscore_support)\n",
        "\n",
        "#### Helpful links\n",
        "- Scikit-learn documentation for logistic regression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "- How Logistic Regression works: https://machinelearningmastery.com/logistic-regression-for-machine-learning/\n",
        "- Feature Scaling: https://scikit-learn.org/stable/modules/preprocessing.html\n",
        "- Training testing splitting: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "- Classification metrics in sklearn: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
        "- Use slack for doubts: https://join.slack.com/t/deepconnectai/shared_invite/zt-givlfnf6-~cn3SQ43k0BGDrG9_YOn4g"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-i4VgviHf_Kk",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ooYDzG4SnErt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "6d1294c7-e568-45a1-8428-9fcc0dc0605f"
      },
      "source": [
        "# Download the dataset from the source\n",
        "!wget https://github.com/DeepConnectAI/challenge-week-3/raw/master/data/diabetes_data.csv"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-30 14:18:36--  https://github.com/DeepConnectAI/challenge-week-3/raw/master/data/diabetes_data.csv\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DeepConnectAI/challenge-week-3/master/data/diabetes_data.csv [following]\n",
            "--2020-08-30 14:18:36--  https://raw.githubusercontent.com/DeepConnectAI/challenge-week-3/master/data/diabetes_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34161 (33K) [text/plain]\n",
            "Saving to: ‘diabetes_data.csv’\n",
            "\n",
            "diabetes_data.csv   100%[===================>]  33.36K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-08-30 14:18:36 (2.34 MB/s) - ‘diabetes_data.csv’ saved [34161/34161]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XqZrgW_if_Kq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "7175c937-3fc8-4fd3-b0b5-190fb9bbb79f"
      },
      "source": [
        "# NOTE: DO NOT CHANGE THE VARIABLE NAME(S) IN THIS CELL\n",
        "# Load the data\n",
        "data = pd.read_csv(\"diabetes_data.csv\")\n",
        "data"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Polyuria</th>\n",
              "      <th>Polydipsia</th>\n",
              "      <th>sudden weight loss</th>\n",
              "      <th>weakness</th>\n",
              "      <th>Polyphagia</th>\n",
              "      <th>Genital thrush</th>\n",
              "      <th>visual blurring</th>\n",
              "      <th>Itching</th>\n",
              "      <th>Irritability</th>\n",
              "      <th>delayed healing</th>\n",
              "      <th>partial paresis</th>\n",
              "      <th>muscle stiffness</th>\n",
              "      <th>Alopecia</th>\n",
              "      <th>Obesity</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>39</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>48</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>58</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>32</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>42</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>520 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  Gender Polyuria  ... Alopecia Obesity     class\n",
              "0     40    Male       No  ...      Yes     Yes  Positive\n",
              "1     58    Male       No  ...      Yes      No  Positive\n",
              "2     41    Male      Yes  ...      Yes      No  Positive\n",
              "3     45    Male       No  ...       No      No  Positive\n",
              "4     60    Male      Yes  ...      Yes     Yes  Positive\n",
              "..   ...     ...      ...  ...      ...     ...       ...\n",
              "515   39  Female      Yes  ...       No      No  Positive\n",
              "516   48  Female      Yes  ...       No      No  Positive\n",
              "517   58  Female      Yes  ...       No     Yes  Positive\n",
              "518   32  Female       No  ...      Yes      No  Negative\n",
              "519   42    Male       No  ...       No      No  Negative\n",
              "\n",
              "[520 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hjCRzhp_f_Kw",
        "colab": {}
      },
      "source": [
        "# Handle categorical/binary columns"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX_HfNKGKeRY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "7b0d41b4-a37b-4f30-b415-49cd97800e55"
      },
      "source": [
        "data=pd.get_dummies(data,drop_first=True)\n",
        "data"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Polyuria_Yes</th>\n",
              "      <th>Polydipsia_Yes</th>\n",
              "      <th>sudden weight loss_Yes</th>\n",
              "      <th>weakness_Yes</th>\n",
              "      <th>Polyphagia_Yes</th>\n",
              "      <th>Genital thrush_Yes</th>\n",
              "      <th>visual blurring_Yes</th>\n",
              "      <th>Itching_Yes</th>\n",
              "      <th>Irritability_Yes</th>\n",
              "      <th>delayed healing_Yes</th>\n",
              "      <th>partial paresis_Yes</th>\n",
              "      <th>muscle stiffness_Yes</th>\n",
              "      <th>Alopecia_Yes</th>\n",
              "      <th>Obesity_Yes</th>\n",
              "      <th>class_Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>520 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  Gender_Male  Polyuria_Yes  ...  Alopecia_Yes  Obesity_Yes  class_Positive\n",
              "0     40            1             0  ...             1            1               1\n",
              "1     58            1             0  ...             1            0               1\n",
              "2     41            1             1  ...             1            0               1\n",
              "3     45            1             0  ...             0            0               1\n",
              "4     60            1             1  ...             1            1               1\n",
              "..   ...          ...           ...  ...           ...          ...             ...\n",
              "515   39            0             1  ...             0            0               1\n",
              "516   48            0             1  ...             0            0               1\n",
              "517   58            0             1  ...             0            1               1\n",
              "518   32            0             0  ...             1            0               0\n",
              "519   42            1             0  ...             0            0               0\n",
              "\n",
              "[520 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tqCVUtIUf_K3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "3c66f3e1-6aa1-458e-8765-e68a891fba39"
      },
      "source": [
        "# Normalize the age feature\n",
        "x = data[['Age']].values\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "data.drop([\"Age\"],axis = 1, inplace = True)\n",
        "data.insert(0,'Age',x_scaled)\n",
        "data"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Polyuria_Yes</th>\n",
              "      <th>Polydipsia_Yes</th>\n",
              "      <th>sudden weight loss_Yes</th>\n",
              "      <th>weakness_Yes</th>\n",
              "      <th>Polyphagia_Yes</th>\n",
              "      <th>Genital thrush_Yes</th>\n",
              "      <th>visual blurring_Yes</th>\n",
              "      <th>Itching_Yes</th>\n",
              "      <th>Irritability_Yes</th>\n",
              "      <th>delayed healing_Yes</th>\n",
              "      <th>partial paresis_Yes</th>\n",
              "      <th>muscle stiffness_Yes</th>\n",
              "      <th>Alopecia_Yes</th>\n",
              "      <th>Obesity_Yes</th>\n",
              "      <th>class_Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.324324</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.567568</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.337838</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.391892</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.594595</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>0.310811</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>0.432432</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>0.567568</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>0.216216</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>0.351351</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>520 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Age  Gender_Male  ...  Obesity_Yes  class_Positive\n",
              "0    0.324324            1  ...            1               1\n",
              "1    0.567568            1  ...            0               1\n",
              "2    0.337838            1  ...            0               1\n",
              "3    0.391892            1  ...            0               1\n",
              "4    0.594595            1  ...            1               1\n",
              "..        ...          ...  ...          ...             ...\n",
              "515  0.310811            0  ...            0               1\n",
              "516  0.432432            0  ...            0               1\n",
              "517  0.567568            0  ...            1               1\n",
              "518  0.216216            0  ...            0               0\n",
              "519  0.351351            1  ...            0               0\n",
              "\n",
              "[520 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Uc-BEzqf_K-",
        "colab": {}
      },
      "source": [
        "# Define your X and y\n",
        "X = data.iloc[:,:-1].values\n",
        "y = data.iloc[:,-1].values"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DIiMrIaajX-Q",
        "colab": {}
      },
      "source": [
        "# Split the dataset into training and testing here\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15,random_state=42)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXEaOsXtKeRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X, weights):\n",
        "    '''Predict class for X.\n",
        "    For the given dataset, predicted vector has only values 0/1\n",
        "    Args:\n",
        "        X : Numpy array (num_samples, num_features)\n",
        "        weights : Model weights for logistic regression\n",
        "    Returns:\n",
        "        Binary predictions : (num_samples,)\n",
        "    '''\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    z = X.dot(weights)\n",
        "    # logits = \n",
        "    y_pred = sigmoid(z)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return y_pred"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28IiA42hKeRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z):\n",
        "        '''Sigmoid function: f:R->(0,1)\n",
        "        Args:\n",
        "            z : A numpy array (num_samples,)\n",
        "        Returns:\n",
        "            A numpy array where sigmoid function applied to every element\n",
        "        '''\n",
        "        ### START CODE HERE\n",
        "        sig_z = 1/(1 + np.exp(-z))\n",
        "        ### END CODE HERE\n",
        "        \n",
        "        assert (z.shape==sig_z.shape), 'Error in sigmoid implementation. Check carefully'\n",
        "        return sig_z"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDVcmUIMKeRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    '''Calculate cross entropy loss\n",
        "    Note: Cross entropy is defined for multiple classes/labels as well\n",
        "    but for this dataset we only need binary cross entropy loss\n",
        "    Args:\n",
        "        y_true : Numpy array of true values (0/1) of size (num_samples,)\n",
        "        y_pred : Numpy array of predicted values (probabilites) of size (num_samples,)\n",
        "    Returns:\n",
        "        Cross entropy loss: A scalar value\n",
        "    '''\n",
        "    # Fix 0 values in y_pred\n",
        "    y_pred = np.maximum(np.full(y_pred.shape, 1e-7), np.minimum(np.full(y_pred.shape, 1-1e-7), y_pred))\n",
        "    \n",
        "    ### START CODE HERE\n",
        "    ce_loss = (y_true * np.log(y_pred)) + ((1-y_true) * np.log(1-y_pred))\n",
        "    ### END CODE HERE\n",
        "    \n",
        "    return ce_loss.mean()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAqkUiaOKeRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def newton_optimization(X, y, max_iterations=25):\n",
        "    '''Implement netwon method for optimizing weights\n",
        "    Args:\n",
        "        X : Numpy array (num_samples, num_features)\n",
        "        max_iterations : Max iterations to update the weights\n",
        "    Returns:\n",
        "        Optimal weights (num_features,)\n",
        "    '''\n",
        "    num_samples = X.shape[0]\n",
        "    num_features = X.shape[1]\n",
        "    # Initialize random weights\n",
        "    weights = np.zeros(num_features,)\n",
        "    # Initialize losses\n",
        "    losses = []\n",
        "    \n",
        "    # Newton Method\n",
        "    for i in range(max_iterations):\n",
        "        # Predict/Calculate probabilties using sigmoid function\n",
        "        y_p = sigmoid(X.dot(weights))\n",
        "        \n",
        "        # Define gradient for J (cost function) i.e. cross entropy loss\n",
        "        gradient = 1./ num_samples * np.dot(X.T,(y_p-y))\n",
        "        \n",
        "        # Define hessian matrix for cross entropy loss\n",
        "        hessian = 1./ num_samples * X.T.dot(np.diag(y_p*(1-y_p))).dot(X)\n",
        "        \n",
        "        # Update the model using hessian matrix and gradient computed\n",
        "        weights -= np.dot(np.linalg.pinv(hessian),gradient)\n",
        "        \n",
        "        # Calculate cross entropy loss\n",
        "        loss = cross_entropy_loss(y, y_p)\n",
        "        # Append it\n",
        "        losses.append(loss)\n",
        "\n",
        "    return weights, losses"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68PosSXnKeRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train weights\n",
        "weights, losses = newton_optimization(X_train, y_train)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1rJpohlKeR0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a679ec5e-f918-471d-d818-bd1e0aadbe42"
      },
      "source": [
        "# Plot the loss curve\n",
        "plt.plot([i+1 for i in range(len(losses))], losses)\n",
        "plt.title(\"Loss curve\")\n",
        "plt.xlabel(\"Iteration num\")\n",
        "plt.ylabel(\"Cross entropy curve\")\n",
        "plt.show()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vChFvGdKeR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d027dba0-2958-4d57-da65-a89d1630771f"
      },
      "source": [
        "our_model_test_acuracy = accuracy_score(y_test, predict(X_test, weights).round())\n",
        "\n",
        "print(f\"\\nAccuracy in testing set by our model: {our_model_test_acuracy}\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy in testing set by our model: 0.9102564102564102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWk1QVLtKeR3",
        "colab_type": "text"
      },
      "source": [
        "#### Compare with the scikit learn implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qhvibx3Xf_LB",
        "colab": {}
      },
      "source": [
        "# Initialize the model\n",
        "model = LogisticRegression(solver='newton-cg', verbose=1)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ndXHgNLxf_LD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "c67872f1-a874-4e2c-bd37-34d0e49112fc"
      },
      "source": [
        "# Fit the model. Wait! We will complete this step for you ;)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=1,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oHOeLfjFjeNh",
        "colab": {}
      },
      "source": [
        "# Predict on testing set X_test\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eE5g0uoYf_LG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bba54432-ccef-49c4-b770-67ed9097ca5c"
      },
      "source": [
        "# Print Accuracy on testing set\n",
        "sklearn_test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nAccuracy in testing set by sklearn model: {sklearn_test_accuracy}\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy in testing set by sklearn model: 0.9102564102564102\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}